{% extends "landing.html" %}

{% block content %}
<section class="tx-container">
    <div class="md-grid md-typeset">
        <div class="-landing__highlights">
            <div class="tx-landing__highlights_text">
                <h2>Examples</h2>
            </div>

            <div class="tx-landing__highlights_grid">
                <a href="/examples/llama-index-weaviate">
                    <div class="feature-cell">
                        <h3>
                            RAG with Llama Index and Weaviate
                        </h3>

                        <p>
                            Use <strong>Llama Index</strong> and <strong>Weaviate</strong> to enhance the capabilities
                            of LLMs with the context of your data.
                        </p>

                        <div class="feature-tags">
                            <div class="feature-tag">RAG</div>
                            <div class="feature-tag">Llama Index</div>
                        </div>
                    </div>
                </a>

                <a href="/examples/finetuning-llama-2">
                    <div class="feature-cell">
                        <h3>
                            Fine-tuning LLMs using Tasks
                        </h3>

                        <p>
                            Fine-tune <strong>Llama 2</strong> on a custom dataset, with QLoRA
                            and your own script, using <strong>Tasks</strong>.
                        </p>

                        <div class="feature-tags">
                            <div class="feature-tag">Fine-tuning</div>
                            <div class="feature-tag">Tasks</div>
                        </div>
                    </div>
                </a>

                <a href="/examples/text-generation-inference">
                    <div class="feature-cell">
                        <h3>
                            Deploying LLMs with TGI
                            <br/><br/>
                        </h3>

                        <p>
                            Deploy LLMs using <strong>Services</strong> and <strong>TGI</strong>, an
                            open-source serving framework by Hugging Face.
                        </p>

                        <div class="feature-tags">
                            <div class="feature-tag">Deploying</div>
                            <div class="feature-tag">Services</div>
                            <div class="feature-tag">TGI</div>
                        </div>
                    </div>
                </a>

                <a href="/examples/stable-diffusion-xl">
                    <div class="feature-cell">
                        <h3>
                            Deploying SDXL using Services
                        </h3>

                        <p>
                            Deploy <strong>Stable Diffusion XL</strong>,
                            with <strong>FastAPI</strong> and <strong>Diffusers</strong>,
                            using <strong>Services</strong>.
                            <br><br>
                        </p>

                        <div class="feature-tags">
                            <div class="feature-tag">Deploying</div>
                            <div class="feature-tag">Services</div>
                        </div>
                    </div>
                </a>

                <a href="/examples/vllm">
                    <div class="feature-cell">
                        <h3>
                            Deploying LLMs with vLLM
                            <br/><br/>
                        </h3>

                        <p>
                            Deploy LLMs with <strong>Services</strong> and <strong>vLLM</strong>,
                            an open-source serving library.

                            <br><br>
                        </p>

                        <div class="feature-tags">
                            <div class="feature-tag">Deploying</div>
                            <div class="feature-tag">Services</div>
                            <div class="feature-tag">vLLM</div>
                        </div>
                    </div>
                </a>
            </div>
        </div>
    </div>
</section>
<br>
<br>
<br>
<br>
{% endblock %}